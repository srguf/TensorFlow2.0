from sklearn.datasets import load_iris
import numpy as np
import tensorflow as tf
from matplotlib import pyplot as plt

# 数据集读入: load_iris().data是一个二维数组，记录这每个特征的细节
# x_data = load_iris().data  oad_iris().data返回的数据默认是float64类型
x_data = load_iris().data.astype('float32')
y_data = load_iris().target
# print(x_data)
# print(y_data)

# 数据集乱序
np.random.seed(110)
np.random.shuffle(x_data)  # shuffle有洗牌的意思
np.random.seed(110)
np.random.shuffle(y_data)

# 分出训练集和测试集
x_train = x_data[:-30]
y_train = y_data[:-30]
x_test = x_data[-30:]
y_test = y_data[-30:]

# 将数据和标签配对，并将其打包
train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)
test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)

# 定义神经网络中可训练参数
w = tf.Variable(tf.random.truncated_normal([4, 3], stddev=0.1, seed=1))  # 单层神经网络，4x3，
# tf.random.truncated_normal函数生成的随机数张量默认是float32
b = tf.Variable(tf.random.truncated_normal([3], stddev=0.1, seed=1))

lr = 0.3  # 学习率
train_loss_results = []  # 将每轮的loss记录在此列表中，为后续loss曲线提供参数
test_acc = []  # 将每轮的acc记录在此列表中
epoch = 500  # 迭代次数
loss_all = 0  # 每轮loss和

# 嵌套循环迭代
for epoch in range(epoch):  # 数据集级别迭代，每个epoch循环一次数据集

    # 训练w，b的部分
    for step, (x_train, y_train) in enumerate(train_db):  # w,b的batch级别迭代，每个step循环一个32，共4次

        # 定义gradient细节部分   本质还是损失函数的导数
        with tf.GradientTape() as tape:
            # 向前传播过程描述
            y = tf.matmul(x_train, w) + b  # y = wx + b 神经网络基本运算
            y = tf.nn.softmax(y)  # 激活函数
            # print(y)  # y是关于3重不同分类的概率结果
            y_ = tf.one_hot(y_train, depth=3)  # 将[0,1,2]转换为one_hot编码tf.one_hot()接收整数类型
            # print(x_train)
            # print(y_train)
            # print(y_)

            loss = tf.reduce_mean(tf.square(y_ - y))  # 每个step的loss     均方损失函数mse(Mean Squared Error)
            # print(loss)
            loss_all += loss.numpy()  # 将每个step计算出的loss累加， 为后续求loss平均提供便利
        grads = tape.gradient(loss, [w, b])  # 梯度下降，获得w[[],...[]]，b[]的导数
        # print(grads)
        """
            
            '''
            tf.Tensor(
            [[7.7 2.6 6.9 2.3]
             [5.5 2.3 4.  1.3]
             [5.  3.断点续训_存取模型  1.6 0.2]
             [5.2 2.7 3.9 1.4]
             [5.1 3.7 1.5 0.4]
             [5.5 2.4 3.7 1. ]
             [6.  2.2 4.  1. ]
             [5.5 2.6 4.4 1.2]
             [6.2 2.9 4.3 1.3]
             [4.9 2.5 4.5 1.7]
             [5.  3.4 1.6 0.4]
             [6.1 2.6 5.6 1.4]
             [6.7 3.1 4.4 1.4]
             [5.7 2.8 4.5 1.3]
             [6.2 3.4 5.4 2.3]
             [5.  3.4 1.5 0.2]
             [5.  2.  3.5 1. ]
             [5.4 3.断点续训_存取模型  4.5 1.5]
             [5.6 2.7 4.2 1.3]
             [6.5 2.8 4.6 1.5]
             [4.4 3.2 1.3 0.2]
             [6.3 3.3 4.7 1.6]
             [6.3 2.3 4.4 1.3]
             [5.8 4.  1.2 0.2]
             [5.7 3.断点续训_存取模型  4.2 1.2]
             [5.  3.5 1.6 0.6]
             [5.2 3.4 1.4 0.2]
             [5.7 2.8 4.1 1.3]
             [6.1 2.8 4.7 1.2]
             [4.6 3.6 1.  0.2]
             [4.7 3.2 1.6 0.2]
             [5.4 3.7 1.5 0.2]], shape=(32, 4), dtype=float32)
            tf.Tensor(
            [[5.6 3.断点续训_存取模型  4.1 1.3]
             [6.7 2.5 5.8 1.8]
             [6.1 2.9 4.7 1.4]
             [7.1 3.断点续训_存取模型  5.9 2.1]
             [5.5 2.4 3.8 1.1]
             [6.5 3.2 5.1 2. ]
             [4.4 3.断点续训_存取模型  1.3 0.2]
             [6.7 3.1 4.7 1.5]
             [6.2 2.8 4.8 1.8]
             [6.7 3.3 5.7 2.5]
             [5.7 2.9 4.2 1.3]
             [6.  2.2 5.  1.5]
             [4.9 2.4 3.3 1. ]
             [6.2 2.2 4.5 1.5]
             [5.  3.6 1.4 0.2]
             [4.8 3.4 1.6 0.2]
             [5.2 4.1 1.5 0.1]
             [6.7 3.3 5.7 2.1]
             [5.1 3.8 1.9 0.4]
             [4.8 3.1 1.6 0.2]
             [5.8 2.7 3.9 1.2]
             [6.9 3.1 5.4 2.1]
             [6.7 3.断点续训_存取模型  5.  1.7]
             [5.  3.3 1.4 0.2]
             [6.3 2.5 5.  1.9]
             [5.4 3.9 1.7 0.4]
             [5.8 2.7 5.1 1.9]
             [4.5 2.3 1.3 0.3]
             [6.3 3.3 6.  2.5]
             [5.4 3.9 1.3 0.4]
             [6.6 2.9 4.6 1.3]
             [5.1 3.5 1.4 0.3]], shape=(32, 4), dtype=float32)
            tf.Tensor(
            [[6.4 2.8 5.6 2.2]
             [7.9 3.8 6.4 2. ]
             [6.5 3.断点续训_存取模型  5.5 1.8]
             [5.1 3.5 1.4 0.2]
             [7.6 3.断点续训_存取模型  6.6 2.1]
             [5.7 2.6 3.5 1. ]
             [6.1 2.8 4.  1.3]
             [4.6 3.1 1.5 0.2]
             [6.4 3.1 5.5 1.8]
             [4.6 3.4 1.4 0.3]
             [5.1 3.8 1.5 0.3]
             [7.2 3.6 6.1 2.5]
             [5.5 4.2 1.4 0.2]
             [4.9 3.1 1.5 0.2]
             [6.3 3.4 5.6 2.4]
             [6.1 3.断点续训_存取模型  4.9 1.8]
             [7.3 2.9 6.3 1.8]
             [6.  2.7 5.1 1.6]
             [4.8 3.4 1.9 0.2]
             [5.1 3.4 1.5 0.2]
             [5.8 2.6 4.  1.2]
             [5.8 2.7 5.1 1.9]
             [6.4 3.2 5.3 2.3]
             [6.4 2.9 4.3 1.3]
             [6.5 3.断点续训_存取模型  5.8 2.2]
             [5.2 3.5 1.5 0.2]
             [6.6 3.断点续训_存取模型  4.4 1.4]
             [7.7 3.8 6.7 2.2]
             [6.5 3.断点续训_存取模型  5.2 2. ]
             [5.  3.2 1.2 0.2]
             [6.3 2.9 5.6 1.8]
             [4.8 3.断点续训_存取模型  1.4 0.3]], shape=(32, 4), dtype=float32)
            tf.Tensor(
            [[4.9 3.断点续训_存取模型  1.4 0.2]
             [6.  3.断点续训_存取模型  4.8 1.8]
             [6.4 2.7 5.3 1.9]
             [6.9 3.1 5.1 2.3]
             [5.4 3.4 1.7 0.2]
             [5.8 2.8 5.1 2.4]
             [4.8 3.断点续训_存取模型  1.4 0.1]
             [7.7 2.8 6.7 2. ]
             [6.9 3.2 5.7 2.3]
             [7.  3.2 4.7 1.4]
             [5.5 3.5 1.3 0.2]
             [5.6 2.5 3.9 1.1]
             [6.7 3.断点续训_存取模型  5.2 2.3]
             [7.7 3.断点续训_存取模型  6.1 2.3]
             [5.6 2.9 3.6 1.3]
             [5.7 2.5 5.  2. ]
             [4.7 3.2 1.3 0.2]
             [6.8 2.8 4.8 1.4]
             [4.6 3.2 1.4 0.2]
             [6.9 3.1 4.9 1.5]
             [5.1 3.8 1.6 0.2]
             [5.  2.3 3.3 1. ]
             [5.7 3.8 1.7 0.3]
             [4.9 3.1 1.5 0.1]], shape=(24, 4), dtype=float32)
            '''
            [[0.88410825 0.09371828 0.02217352]
             [0.05865642 0.12896433 0.8123792 ]
             [0.02505776 0.11155712 0.8633851 ]
             [0.04701217 0.12203837 0.8309494 ]
             [0.90083104 0.08021683 0.01895219]
             [0.01764974 0.06733365 0.91501665]
             [0.88510936 0.09311176 0.02177891]
             [0.006127   0.07499988 0.91887313]
             [0.02037919 0.07963801 0.89998275]
             [0.16497618 0.24128765 0.5937362 ]
             [0.9377302  0.05358227 0.0086876 ]
             [0.16796418 0.2621289  0.5699069 ]
             [0.033154   0.10477521 0.86207074]
             [0.01485492 0.09387711 0.89126796]
             [0.27995428 0.23531796 0.48472768]
             [0.02060232 0.09222286 0.88717484]
             [0.90784043 0.07361832 0.01854129]
             [0.0976356  0.23359612 0.6687683 ]
             [0.8971421  0.07971492 0.02314293]
             [0.10718934 0.20929055 0.6835201 ]
             [0.9330541  0.05255507 0.0143909 ]
             [0.2380755  0.27967393 0.48225057]
             [0.93196017 0.05563184 0.01240804]
             [0.886521   0.09134779 0.02213129]], shape=(24, 3), dtype=float32)
            '''
            print(y_train)
            tf.Tensor([2 1 0 1 0 1 1 1 1 2 0 2 1 1 2 0 1 1 1 1 0 1 1 0 1 0 0 1 1 0 0 0], shape=(32,), dtype=int32)
            tf.Tensor([1 2 1 2 1 2 0 1 2 2 1 2 1 1 0 0 0 2 0 0 1 2 1 0 2 0 2 0 2 0 1 0], shape=(32,), dtype=int32)
            tf.Tensor([2 2 2 0 2 1 1 0 2 0 0 2 0 0 2 2 2 1 0 0 1 2 2 1 2 0 1 2 2 0 2 0], shape=(32,), dtype=int32)
            tf.Tensor([0 2 2 2 0 2 0 2 2 1 0 1 2 2 1 2 0 1 0 1 0 1 0 0], shape=(24,), dtype=int32)
            '''
            # print(y_)
            '''
            tf.Tensor(
            [[0. 0. 1.]
             [0. 1. 0.]
             [1. 0. 0.]
             [0. 1. 0.]
             [1. 0. 0.]
             [0. 1. 0.]
             [0. 1. 0.]
             [0. 1. 0.]
             [0. 1. 0.]
             [0. 0. 1.]
             [1. 0. 0.]
             [0. 0. 1.]
             [0. 1. 0.]
             [0. 1. 0.]
             [0. 0. 1.]
             [1. 0. 0.]
             [0. 1. 0.]
             [0. 1. 0.]
             [0. 1. 0.]
             [0. 1. 0.]
             [1. 0. 0.]
             [0. 1. 0.]
             [0. 1. 0.]
             [1. 0. 0.]
             [0. 1. 0.]
             [1. 0. 0.]
             [1. 0. 0.]
             [0. 1. 0.]
             [0. 1. 0.]
             [1. 0. 0.]
             [1. 0. 0.]
             [1. 0. 0.]], shape=(32, 3), dtype=float32)
            tf.Tensor(
            [[0. 1. 0.]
             [0. 0. 1.]
             [0. 1. 0.]
             [0. 0. 1.]
             [0. 1. 0.]
             [0. 0. 1.]
             [1. 0. 0.]
             [0. 1. 0.]
             [0. 0. 1.]
             [0. 0. 1.]
             [0. 1. 0.]
             [0. 0. 1.]
             [0. 1. 0.]
             [0. 1. 0.]
             [1. 0. 0.]
             [1. 0. 0.]
             [1. 0. 0.]
             [0. 0. 1.]
             [1. 0. 0.]
             [1. 0. 0.]
             [0. 1. 0.]
             [0. 0. 1.]
             [0. 1. 0.]
             [1. 0. 0.]
             [0. 0. 1.]
             [1. 0. 0.]
             [0. 0. 1.]
             [1. 0. 0.]
             [0. 0. 1.]
             [1. 0. 0.]
             [0. 1. 0.]
             [1. 0. 0.]], shape=(32, 3), dtype=float32)
            tf.Tensor(
            [[0. 0. 1.]
             [0. 0. 1.]
             [0. 0. 1.]
             [1. 0. 0.]
             [0. 0. 1.]
             [0. 1. 0.]
             [0. 1. 0.]
             [1. 0. 0.]
             [0. 0. 1.]
             [1. 0. 0.]
             [1. 0. 0.]
             [0. 0. 1.]
             [1. 0. 0.]
             [1. 0. 0.]
             [0. 0. 1.]
             [0. 0. 1.]
             [0. 0. 1.]
             [0. 1. 0.]
             [1. 0. 0.]
             [1. 0. 0.]
             [0. 1. 0.]
             [0. 0. 1.]
             [0. 0. 1.]
             [0. 1. 0.]
             [0. 0. 1.]
             [1. 0. 0.]
             [0. 1. 0.]
             [0. 0. 1.]
             [0. 0. 1.]
             [1. 0. 0.]
             [0. 0. 1.]
             [1. 0. 0.]], shape=(32, 3), dtype=float32)
            tf.Tensor(
            [[1. 0. 0.]
             [0. 0. 1.]
             [0. 0. 1.]
             [0. 0. 1.]
             [1. 0. 0.]
             [0. 0. 1.]
             [1. 0. 0.]
             [0. 0. 1.]
             [0. 0. 1.]
             [0. 1. 0.]
             [1. 0. 0.]
             [0. 1. 0.]
             [0. 0. 1.]
             [0. 0. 1.]
             [0. 1. 0.]
             [0. 0. 1.]
             [1. 0. 0.]
             [0. 1. 0.]
             [1. 0. 0.]
             [0. 1. 0.]
             [1. 0. 0.]
             [0. 1. 0.]
             [1. 0. 0.]
             [1. 0. 0.]], shape=(24, 3), dtype=float32)
            '''
            
            # print(loss)
            '''
            tf.Tensor(0.12646578, shape=(), dtype=float32)
            tf.Tensor(0.18786244, shape=(), dtype=float32)
            tf.Tensor(0.08034496, shape=(), dtype=float32)
            tf.Tensor(0.09661084, shape=(), dtype=float32)
            '''
    
        print(grads)
        '''
        [<tf.Tensor: shape=(4, 3), dtype=float32, numpy=
        array([[ 0.03845667, -0.4298392 ,  0.39138255],
               [ 0.01224174, -0.19513418,  0.18289243],
               [ 0.0366748 , -0.31603917,  0.27936438],
               [ 0.01193974, -0.09525965,  0.08331991]], dtype=float32)>, <tf.Tensor: shape=(3,), dtype=float32, 
        numpy=array([ 0.00582555, -0.07357551,  0.06774997], dtype=float32)>]
        
        [<tf.Tensor: shape=(4, 3), dtype=float32, numpy=
        array([[-0.10078374,  0.34898126, -0.24819759],
               [-0.06677786,  0.17829242, -0.11151458],
               [-0.03383032,  0.24642378, -0.21259347],
               [-0.00803813,  0.0889153 , -0.08087718]], dtype=float32)>, <tf.Tensor: shape=(3,), dtype=float32, 
        numpy=array([-0.02007328,  0.05818065, -0.03810737], dtype=float32)>]
         
        [<tf.Tensor: shape=(4, 3), dtype=float32, numpy=
        array([[ 0.0795635 ,  0.21362218, -0.29318568],
               [ 0.0316899 ,  0.10574418, -0.13743407],
               [ 0.06600212,  0.19537371, -0.2613758 ],
               [ 0.02279087,  0.07257807, -0.09536894]], dtype=float32)>, <tf.Tensor: shape=(3,), dtype=float32, 
        numpy=array([ 0.01175615,  0.03023587, -0.04199202], dtype=float32)>]
               
               [<tf.Tensor: shape=(4, 3), dtype=float32, numpy=
        array([[-0.0320557 , -0.16695938,  0.19901505],
               [-0.01828999, -0.07312401,  0.09141399],
               [-0.01325836, -0.11723411,  0.13049248],
               [-0.00213726, -0.03490484,  0.03704209]], dtype=float32)>, <tf.Tensor: shape=(3,), dtype=float32, 
        numpy=array([-0.00570702, -0.02686989,  0.03257691], dtype=float32)>]
        '''
        """

        # 实现梯度更新w1 = w1 - lr * w1_grad  b = b - lr * b_grad
        w.assign_sub(lr * grads[0])
        b.assign_sub(lr * grads[1])

    # 在本次epoch中打印loss信息，并将其结果保存在数组中
    print("Epoch:{}\nLoss:{}".format(epoch, loss_all / 4))  # 输出这个epoch中每个step的loss的平均值
    train_loss_results.append(loss_all / 4)  # 将每个step的平均loss记录在此变量中
    loss_all = 0  # 格式化

    # 在本次epoch中对训练后的模型进行测试的部分
    total_correct = 0  # 预测正确的样本个数
    total_number = 0  # 测试的总样本数
    for x_test, y_test in test_db:
        # 使用更新后的参数w,b进行预测
        y = tf.matmul(x_test, w) + b
        y = tf.nn.softmax(y)
        # print(x_test)
        # print(y)  # 是个二维数组

        # 获取预测结果，并进行数据类型的修改
        pred = tf.argmax(y, axis=1)  # 返回y中最大值的索引，即预测的分类
        pred = tf.cast(pred, dtype=y_test.dtype)  # 将pred转换为y_test的数据类型

        # 将修改后的y与y_test进行结果比对，并获得正确个数
        correct = tf.cast(tf.equal(pred, y_test), dtype=tf.int32)  # 若分类正确，则为1，否则为0，并将bool类型的结果转换为int型
        correct = tf.reduce_sum(correct)  # 将每个batch的correct数加起来
        total_correct += int(correct)  # 将所有batch的correct加起来

        # total_number为测试集的总样本数，也就是x_test的行数，shape[0]返回行数
        total_number += x_test.shape[0]

    # 本次epoch的的测试精度的计算，并保存结果在数组中和输出
    acc = total_correct / total_number  # 总准确率等于total_correct/total_number
    test_acc.append(acc)
    print("Test_acc:", acc)
    print("-" * 50)


#现在我们通过train_loss_results和test_acc这两个列表可以知道每次epoch的loss和acc
# 绘制loss曲线
plt.title("Loss Function Curve")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.plot(train_loss_results, label="$loss$")
plt.legend()
plt.show()

# 绘制Accuracy曲线
plt.title("Loss Function Curve")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.plot(test_acc, label="$Accuracy$")
plt.legend()
plt.show()
